{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bbeb96d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-30T07:40:20.531940Z",
     "start_time": "2022-08-30T07:40:14.145094Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2a8ab11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-30T07:40:27.575376Z",
     "start_time": "2022-08-30T07:40:20.532941Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-small\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecbe55ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-29T14:12:51.009721Z",
     "start_time": "2022-08-29T14:12:39.839383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> User:hello, how are you ?\n",
      "DialoGPT: Hello, how are you?\n"
     ]
    }
   ],
   "source": [
    "# encode the new user input, add the eos_token and return a tensor in Pytorch\n",
    "new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n",
    "\n",
    "# append the new user input tokens to the chat history\n",
    "# bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
    "bot_input_ids = new_user_input_ids\n",
    "\n",
    "# generated a response while limiting the total chat history to 1000 tokens, \n",
    "chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "# pretty print last ouput tokens from bot\n",
    "print(\"DialoGPT: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef2a19ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-30T07:40:27.767548Z",
     "start_time": "2022-08-30T07:40:27.576377Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"Data/empatheticdialogues/train.csv\", on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "842ab89e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-30T07:40:27.782717Z",
     "start_time": "2022-08-30T07:40:27.769549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (76668, 8)\n",
      "Columns Index(['conv_id', 'utterance_idx', 'context', 'prompt', 'speaker_idx',\n",
      "       'utterance', 'selfeval', 'tags'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape\", df_train.shape)\n",
    "print(\"Columns\", df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc417b14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-30T07:40:27.813573Z",
     "start_time": "2022-08-30T07:40:27.784721Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I remember going to the fireworks with my best friend. There was a lot of people_comma_ but it only felt like us in the world.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"prompt\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c057c161",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-30T07:40:27.829583Z",
     "start_time": "2022-08-30T07:40:27.814575Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I remember going to see the fireworks with my best friend. It was the first time we ever spent time alone together. Although there was a lot of people_comma_ we felt like the only people in the world.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"utterance\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e823873",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-30T07:40:28.852760Z",
     "start_time": "2022-08-30T07:40:27.830583Z"
    }
   },
   "outputs": [],
   "source": [
    "n_context = 3\n",
    "\n",
    "columns_name = [\"response\"] + [\"context\"+str(i) for i in range(n_context)]\n",
    "\n",
    "save_dict_list = []\n",
    "for conv_id, df_conv in df_train.groupby(\"conv_id\"):\n",
    "    \n",
    "    total_iter = df_conv.shape[0] - n_context\n",
    "    \n",
    "    if total_iter > 0:\n",
    "    \n",
    "        all_conversation_list = df_conv[\"utterance\"].tolist()\n",
    "\n",
    "        for i in range(total_iter):\n",
    "            conversation_list = all_conversation_list[(i):(i+n_context)]\n",
    "            response_list = [all_conversation_list[i+n_context]]\n",
    "\n",
    "            my_dict = dict(zip(columns_name, response_list + conversation_list))\n",
    "            save_dict_list.append(my_dict)\n",
    "            \n",
    "df_conv_tune = pd.DataFrame(save_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1d1fc82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-30T07:40:28.868749Z",
     "start_time": "2022-08-30T07:40:28.853761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (23281, 4)\n",
      "Columns Index(['response', 'context0', 'context1', 'context2'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape\", df_conv_tune.shape)\n",
    "print(\"Columns\", df_conv_tune.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca1f9920",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-30T07:46:50.623504Z",
     "start_time": "2022-08-30T07:46:46.987606Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer_tc = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model_tc = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5db7ad62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-30T07:58:21.243419Z",
     "start_time": "2022-08-30T07:58:21.209398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LABEL_1'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer_tc(\"What are you saying ? I do not Understand\", return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    logits = model_tc(**inputs).logits\n",
    "\n",
    "predicted_class_id = logits.argmax().item()\n",
    "model_tc.config.id2label[predicted_class_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a2665331",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-30T07:58:22.172406Z",
     "start_time": "2022-08-30T07:58:22.153728Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0308, 0.0556]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "57f6732a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-30T07:56:22.461746Z",
     "start_time": "2022-08-30T07:56:22.435859Z"
    }
   },
   "outputs": [],
   "source": [
    "output = model_tc(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d114424",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-30T07:56:22.746383Z",
     "start_time": "2022-08-30T07:56:22.739376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[0.1044, 0.0261]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1262ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
